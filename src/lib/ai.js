const OpenAI = require('openai');
const fs = require('fs');
const path = require('path');
require('dotenv').config({ path: path.join(__dirname, '..', '..', '.env') });

if (!process.env.OPENAI_API_KEY) {
  console.error('\x1b[31mâœ— OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\x1b[0m');
  console.error('\x1b[33m  1. í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— .env íŒŒì¼ì„ ìƒì„±í•˜ì„¸ìš”');
  console.error('  2. OPENAI_API_KEY=sk-... í˜•ì‹ìœ¼ë¡œ í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”');
  console.error('  3. https://platform.openai.com/api-keys ì—ì„œ í‚¤ë¥¼ ë°œê¸‰ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤\x1b[0m');
  process.exit(1);
}

const client = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

const handleApiError = (e) => {
  if (e?.status === 401 || e?.code === 'invalid_api_key') {
    throw new Error('OpenAI API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. .env íŒŒì¼ì˜ OPENAI_API_KEYë¥¼ í™•ì¸í•˜ì„¸ìš”.');
  }
  if (e?.status === 429) {
    throw new Error('API ìš”ì²­ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ê±°ë‚˜ ìš”ê¸ˆì œë¥¼ í™•ì¸í•˜ì„¸ìš”.');
  }
  if (e?.status === 403) {
    throw new Error('API í‚¤ì— í•´ë‹¹ ëª¨ë¸ ì ‘ê·¼ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤. OpenAI ëŒ€ì‹œë³´ë“œì—ì„œ ê¶Œí•œì„ í™•ì¸í•˜ì„¸ìš”.');
  }
  throw e;
};

const CONFIG_PATH = path.join(__dirname, '..', '..', 'config', 'prompt-config.json');

const loadConfig = () => {
  return JSON.parse(fs.readFileSync(CONFIG_PATH, 'utf-8'));
};

const MODELS = [
  // GPT-4o
  'gpt-4o-mini', 'gpt-4o',
  // GPT-4.1
  'gpt-4.1-nano', 'gpt-4.1-mini', 'gpt-4.1',
  // GPT-5
  'gpt-5-nano', 'gpt-5-mini', 'gpt-5',
  // GPT-5.1
  'gpt-5.1', 'gpt-5.1-codex-mini', 'gpt-5.1-codex',
  // GPT-5.2
  'gpt-5.2', 'gpt-5.2-pro', 'gpt-5.2-codex',
  // Reasoning
  'o3-mini', 'o3', 'o3-pro', 'o4-mini',
];

// reasoning ëª¨ë¸ì€ temperatureë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŒ
const REASONING_MODELS = /^(o[1-9]|o\d+-)/;
const isReasoningModel = (model) => REASONING_MODELS.test(model);

/**
 * ë¸”ë¡œê·¸ ê¸€ ì´ˆì•ˆ ìƒì„±
 * @param {string} topic - ì£¼ì œ
 * @param {Object} [options]
 * @param {string} [options.tone] - ë§íˆ¬
 * @param {number} [options.length] - ëŒ€ëµì ì¸ ê¸€ì ìˆ˜
 * @param {string} [options.model] - ëª¨ë¸ëª…
 * @returns {Promise<{title: string, content: string, tags: string}>}
 */
const generatePost = async (topic, options = {}) => {
  const config = loadConfig();
  const {
    tone = config.defaultTone,
    length = config.defaultLength,
    model = config.defaultModel,
  } = options;

  let res;
  try {
    res = await client.chat.completions.create({
      model,
      messages: [
        { role: 'system', content: config.systemPrompt },
        {
          role: 'user',
          content: `ì£¼ì œ: ${topic}
ë§íˆ¬: ${tone}
ë¶„ëŸ‰: ì•½ ${length}ì

ì‘ì„± ìš”êµ¬ì‚¬í•­:
- ì œëª©ì€ ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ í¬í•¨í•˜ë©´ì„œ í´ë¦­ì„ ìœ ë„í•˜ëŠ” í˜•íƒœë¡œ ì‘ì„± (ìˆ«ì í™œìš© ê¶Œì¥)
- ë³¸ë¬¸ì€ ë„ì…ë¶€ â†’ ë²ˆí˜¸ ë§¤ê¸´ h2 ì†Œì œëª©ë“¤ â†’ ìì£¼ ë¬»ëŠ” ì§ˆë¬¸(h3) â†’ ë§ˆë¬´ë¦¬(h3) êµ¬ì¡°
- ê° ì†Œì œëª© ì„¹ì…˜ì—ëŠ” ì„¤ëª… + ë¶ˆë¦¿ í¬ì¸íŠ¸ + ğŸ‘‰ íŒ í¬í•¨
- íƒœê·¸ëŠ” ê²€ìƒ‰ ìœ ì…ì— íš¨ê³¼ì ì¸ í‚¤ì›Œë“œ 5~7ê°œ

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{"title": "ê¸€ ì œëª©", "content": "<p>HTML ë³¸ë¬¸...</p>", "tags": "íƒœê·¸1,íƒœê·¸2,íƒœê·¸3,íƒœê·¸4,íƒœê·¸5"}`,
        },
      ],
      response_format: { type: 'json_object' },
      ...(!isReasoningModel(model) && { temperature: 0.7 }),
    });
  } catch (e) {
    handleApiError(e);
  }

  return JSON.parse(res.choices[0].message.content);
};

/**
 * ê¸€ ìˆ˜ì •
 * @param {string} content - í˜„ì¬ HTML ë³¸ë¬¸
 * @param {string} instruction - ìˆ˜ì • ì§€ì‹œ
 * @returns {Promise<{title: string, content: string, tags: string}>}
 */
const revisePost = async (content, instruction, model) => {
  const config = loadConfig();
  model = model || config.defaultModel;

  let res;
  try {
    res = await client.chat.completions.create({
      model,
      messages: [
        { role: 'system', content: config.systemPrompt },
        {
          role: 'user',
          content: `ë‹¤ìŒ ê¸€ì„ ìˆ˜ì •í•´ì£¼ì„¸ìš”.

ìˆ˜ì • ì§€ì‹œ: ${instruction}

í˜„ì¬ ë³¸ë¬¸:
${content}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{"title": "ìˆ˜ì •ëœ ì œëª©", "content": "<p>ìˆ˜ì •ëœ HTML ë³¸ë¬¸...</p>", "tags": "íƒœê·¸1,íƒœê·¸2,íƒœê·¸3,íƒœê·¸4,íƒœê·¸5"}`,
        },
      ],
      response_format: { type: 'json_object' },
      ...(!isReasoningModel(model) && { temperature: 0.7 }),
    });
  } catch (e) {
    handleApiError(e);
  }

  return JSON.parse(res.choices[0].message.content);
};

/**
 * ììœ  ëŒ€í™”
 * @param {Array<{role: string, content: string}>} messages
 * @returns {Promise<string>}
 */
const chat = async (messages, model) => {
  const config = loadConfig();
  model = model || config.defaultModel;

  let res;
  try {
    res = await client.chat.completions.create({
      model,
      messages: [
        { role: 'system', content: 'ë‹¹ì‹ ì€ ë¸”ë¡œê·¸ ê¸€ì“°ê¸°ë¥¼ ë•ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì£¼ì œ ë…¼ì˜, ì•„ì´ë””ì–´ ë¸Œë ˆì¸ìŠ¤í† ë°, ê¸€ êµ¬ì¡° ì œì•ˆ ë“±ì„ ë„ì™€ì¤ë‹ˆë‹¤. í•œêµ­ì–´ë¡œ ëŒ€í™”í•˜ì„¸ìš”.' },
        ...messages,
      ],
      ...(!isReasoningModel(model) && { temperature: 0.7 }),
    });
  } catch (e) {
    handleApiError(e);
  }

  return res.choices[0].message.content;
};

module.exports = { generatePost, revisePost, chat, MODELS, loadConfig };
